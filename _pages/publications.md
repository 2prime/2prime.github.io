---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---


I just list selected publication here. For a full list, you can view on <u><a href="https://scale-lab-northwestern.github.io/publications/">my lab homepage</a></u> and <u><a href="https://scholar.google.com/citations?user=NmhvVBgAAAAJ">my Google Scholar profile</a>.</u>


### Selected Publication
- Jasen Lai, Sifan Wang, Chunmei Wang, **Yiping Lu**, Unveiling the Scaling Law of PINNs under Non-Euclidean Geometry, *submitted, 2025*

<mark color='orange'>The first algorithm that enables a predictable scaling law for PINNs.</mark>

- Zexi Fan, Yan Sun, Shihao Yang, **Yiping Lu** [Physics-Informed Inference Time Scaling via
Simulation-Calibrated Scientific Machine Learning](https://arxiv.org/abs/2504.16172), *submitted, 2025* [[slides]](https://2prime.github.io/files/scasml.pdf)

<mark color='orange'>The first inference time scaling algorithm for solving PDEs, which means you can improve the result at inference time without retraining/fine-tune the network.</mark>

- Ruihan Xu, **Yiping Lu**. [What is a Sketch-and-Precondition Derivation for Low-Rank Approximation? Inverse Power Error or Inverse Power Estimation?](https://arxiv.org/abs/2502.07993), *submitted, 2025* [[slides]](https://2prime.github.io/files/sketchandprecondition.pdf)
- Ruihan Xu, **Yiping Lu**. [Randomized Iterative Solver as Iterative Refinement: A Simple Fix Towards Backward Stability](https://2prime.github.io/files/SIRR.pdf), *Artificial Intelligence and Statistics (AISTATS), 2025*
- **Yiping Lu**, Daozhe Lin, Qiang Du. [Which Spaces can be Embedded in $L_p$-type Reproducing Kernel Banach Space? A Characterization via Metric Entropy](https://2prime.github.io/files/EmbeddingRKBS_preprint.pdf), *Submitted*
- **Yiping Lu**, Jiajin Li, Lexing Ying, Jose Blancet. [Synthetic Principal Component Design: Fast Covariate Balancing with Synthetic Controls](https://arxiv.org/pdf/2211.15241),  40th Conference on Uncertainty in Artificial Intelligence (UAI 2024) <font color='red'>[Oral]</font>.
  
<mark color='orange'>Links covariate balancing in causal inference with phase retrival in CroEM. Algorithmic idea is clustering is the largest eigenvector that separates data. The smallest eigenvector can help you to separate data into to similar group thus can be used for causal inference!</mark>

- Haotian Ye, Ruichen Li, Yuntian Gu, **Yiping Lu**, Di He, Liwei Wang. [$O(N^2)$ Representation of General Continuous Anti-symmetric Function](https://arxiv.org/abs/2402.15167), *submitted*, 2024.
- Yihang Chen, Fanghui Liu, **Yiping Lu**, Grigorios Chrysos, Volkan Cevher. [Generalization Guarantees of Deep ResNets in the Mean-Field Regime](https://openreview.net/forum?id=tMzPZTvz2H), International Conference on Learning Representations(ICLR) 2024, <font color='red'>[Spotlight]</font>
- Jose Blanchet, Haoxuan Chen, **Yiping Lu**, Lexing Ying. [When can Regression-Adjusted Control Variates Help? Rare Events, Sobolev Embedding and Minimax Optimality](https://arxiv.org/abs/2305.16527) (alphabetical order) Thirty-seventh Conference on Neural Information Processing Systems (Neurips) 2023

<mark color='orange'>The optimal quadrature rule. We find out text-book algorithm is not optimal. Combine the function approximation quadrature rule and Monte Carlo is the optimal one. The optimality is also relates if the function has a finite variance tail. </mark>

- Jikai Jin, **Yiping Lu**, Jose Blanchet, Lexing Ying [Minimax Optimal Kernel Operator Learning via Multilevel Training](https://arxiv.org/pdf/2209.14430) Eleventh  International Conference on Learning Representations(ICLR) 2023  <font color='red'>[Spotlight]</font> [[slides]](https://2prime.github.io/files/oplearning.pdf)
- **Yiping Lu**, Haoxuan Chen, Jianfeng Lu, Lexing Ying, Jose Blanchet. [Machine Learning For Elliptic PDEs: Fast Rate Generalization Bound, Neural Scaling Law and Minimax Optimality](https://arxiv.org/pdf/2110.06897). 10th International Conference on Learning Representations(ICLR) 2022 [[slides]](https://2prime.github.io/files/mlpde.pdf)
- **Yiping Lu**, Wenlong Ji, Zachary Izzo, Lexing Ying, [Importance Tempering: Group Robustness for Overparameterized Models](https://arxiv.org/pdf/2209.08745)
- Wenlong Ji, **Yiping Lu**, Yiliang Zhang, Zhun Deng, Weijie J Su. [An Unconstrained Layer-Peeled Perspective on Neural Collapse](https://arxiv.org/pdf/2110.02796). Tenth  International Conference on Learning Representations(ICLR) 2022

<mark color='orange'>Show that neural collapse is the implicit bias of Logistic loss and show why logisitic loss is bad for data imbalance.</mark>

  
- **Yiping Lu**, Chao Ma, Yulong Lu, Jianfeng Lu, Lexing Ying. "[A Mean-field Analysis of Deep ResNet and Beyond: Towards Provable Optimization Via Overparameterization From Depth](https://arxiv.org/pdf/2003.05508)" Thirty-seventh International Conference on Machine Learning (ICML), 2020

<mark color='orange'>The first mean-field type convergence results for deep nets. </mark>

- Dinghuai Zhang\*, Tianyuan Zhang\*, **Yiping Lu** \*, Zhanxing Zhu, Bin Dong. "[You Only Propagate Once: Painless Adversarial Training Using Maximal Principle](https://arxiv.org/pdf/1905.00877)" (*equal contribution) 33rd Annual Conference on Neural Information Processing Systems (NeurIPS) 2019.
- Zichao long\*, **Yiping Lu** \*, Xianzhong Ma\*, Bin Dong. "[PDE-Net:Learning PDEs From Data](https://arxiv.org/pdf/1710.09668)", Thirty-fifth International Conference on Machine Learning (ICML), 2018(*equal contribution)
- **Yiping Lu**, Aoxiao Zhong, Quanzheng Li, Bin Dong. "[Beyond Finite Layer Neural Network:Bridging Deep Architects and Numerical Differential Equations](https://arxiv.org/pdf/1710.10121)" Thirty-fifth International Conference on Machine Learning (ICML), 2018

<mark color='orange'>The first papers that considers the NN as approximation to the ODE/PDE. Residual connection = ODE, conv filter = PDE. </mark>


<br> 
<br> 

